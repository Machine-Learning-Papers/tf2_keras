{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_moons\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "assert tf.__version__ == '2.0.0-alpha0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Enabled (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = [[2., 2.],\n",
    "     [1., 0.]]\n",
    "\n",
    "m = tf.matmul(x, x)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000,\n",
    "                  noise=0.1,\n",
    "                  shuffle=True,\n",
    "                  random_state=0,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(8, input_shape=(2,), activation='tanh'),\n",
    "    Dense(2, activation='tanh'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.1),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model is a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = Input(shape=(2, ))\n",
    "x1 = Dense(16, activation='tanh')(ins)\n",
    "x2 = Dense(8, activation='tanh')(x1)\n",
    "x3 = Dense(2, activation='tanh')(x2)\n",
    "outs = Dense(1, activation='sigmoid')(x3)\n",
    "\n",
    "model1 = Model(inputs=ins, outputs=outs)\n",
    "model2 = Model(inputs=ins, outputs=x3)\n",
    "\n",
    "\n",
    "model1.compile(optimizer=Adam(lr=0.005),\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X, y, epochs=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inner = model2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X_inner[:,0], y=X_inner[:,1], hue=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Class + manual loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_1 = Dense(16, activation='tanh')\n",
    "        self.dense_2 = Dense(8, activation='tanh')\n",
    "        self.dense_3 = Dense(2)\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        return self.dense_3(x)\n",
    "\n",
    "model3 = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.01)\n",
    "loss = SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model3(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(y, logits).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(inputs)\n",
    "        loss_value = loss(targets, logits)\n",
    "    return tape.gradient(loss_value, model.variables)\n",
    "\n",
    "grad(model3, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset = dataset.shuffle(len(X)*2).repeat().batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "accuracy_history = []\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for (i, (data, labels)) in enumerate(dataset.take(1000)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model3(data)\n",
    "        loss_value = loss(labels, logits)\n",
    "\n",
    "    loss_history.append(loss_value.numpy())\n",
    "    \n",
    "    grads = tape.gradient(loss_value, model3.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(grads, model3.trainable_variables))\n",
    "        \n",
    "    acc.update_state(labels, logits)\n",
    "    accuracy = acc.result().numpy()\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration: {}, Loss: {:0.3}, Acc: {:0.3}\".format(i, loss_value.numpy(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.plot(accuracy_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "    for i in tf.range(max_num):\n",
    "        if tf.equal(i % 3, 0):\n",
    "            print('Fizz')\n",
    "        elif tf.equal(i % 5, 0):\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(i.numpy())\n",
    "\n",
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "    if x > 0:\n",
    "        x = x * x\n",
    "    else:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable Eager Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[2., 2.],\n",
    "     [1., 0.]]\n",
    "\n",
    "m = tf.matmul(x, x)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "    for i in tf.range(max_num):\n",
    "        if tf.equal(i % 3, 0):\n",
    "            print('Fizz')\n",
    "        elif tf.equal(i % 5, 0):\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(i)\n",
    "\n",
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(max_num):\n",
    "    for i in tf.range(max_num):\n",
    "        if tf.equal(i % 3, 0):\n",
    "            print('Fizz')\n",
    "        elif tf.equal(i % 5, 0):\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(i)\n",
    "\n",
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "    if x > 0:\n",
    "        x = x * x\n",
    "    else:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.autograph.to_code(fizzbuzz.python_function, experimental_optional_features=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've seen, now that we have disabled eager execution our previous models started to throw errors. Go ahead and create a new model `model4` and train it.\n",
    "\n",
    "- create a sequential model, any architecture you'd like\n",
    "- compile it\n",
    "- fit it on `X` and `y` for 10 epochs\n",
    "- run `model4(X)`\n",
    "    - Does the model behave like a function?\n",
    "    - Do you get the same results as you got above with `model(X)`?\n",
    "- run `model4.predict(X)`:\n",
    "    - what results do you get in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
